{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n",
      "0.12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "\n",
    "\n",
    "_SAMPLE_DIR = \"data\"\n",
    "\n",
    "SAMPLE_WAV_SPEECH_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\"  # noqa: E501\n",
    "SAMPLE_WAV_SPEECH_PATH = os.path.join(_SAMPLE_DIR, \"speech.wav\")\n",
    "\n",
    "os.makedirs(_SAMPLE_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def _fetch_data():\n",
    "    uri = [\n",
    "        (SAMPLE_WAV_SPEECH_URL, SAMPLE_WAV_SPEECH_PATH),\n",
    "    ]\n",
    "    for url, path in uri:\n",
    "        with open(path, \"wb\") as file_:\n",
    "            file_.write(requests.get(url).content)\n",
    "\n",
    "\n",
    "_fetch_data()\n",
    "\n",
    "\n",
    "def _get_sample(path, resample=None):\n",
    "    effects = [[\"remix\", \"1\"]]\n",
    "    if resample:\n",
    "        effects.extend(\n",
    "            [\n",
    "                [\"lowpass\", f\"{resample // 2}\"],\n",
    "                [\"rate\", f\"{resample}\"],\n",
    "            ]\n",
    "        )\n",
    "    return torchaudio.sox_effects.apply_effects_file(path, effects=effects)\n",
    "\n",
    "\n",
    "def get_speech_sample(*, resample=None):\n",
    "    return _get_sample(SAMPLE_WAV_SPEECH_PATH, resample=resample)\n",
    "\n",
    "\n",
    "def get_spectrogram(\n",
    "    n_fft=400,\n",
    "    win_len=None,\n",
    "    hop_len=None,\n",
    "    power=2.0,\n",
    "):\n",
    "    waveform, _ = get_speech_sample()\n",
    "    spectrogram = T.Spectrogram(\n",
    "        n_fft=n_fft,\n",
    "        win_length=win_len,\n",
    "        hop_length=hop_len,\n",
    "        center=True,\n",
    "        pad_mode=\"reflect\",\n",
    "        power=power,\n",
    "    )\n",
    "    return spectrogram(waveform)\n",
    "\n",
    "\n",
    "def plot_spectrogram(spec, title=None, ylabel=\"freq_bin\", aspect=\"auto\", xmax=None):\n",
    "    fig, axs = plt.subplots(1, 1)\n",
    "    axs.set_title(title or \"Spectrogram (db)\")\n",
    "    axs.set_ylabel(ylabel)\n",
    "    axs.set_xlabel(\"frame\")\n",
    "    im = axs.imshow(librosa.power_to_db(spec), origin=\"lower\", aspect=aspect)\n",
    "    if xmax:\n",
    "        axs.set_xlim((0, xmax))\n",
    "    fig.colorbar(im, ax=axs)\n",
    "    plt.show(block=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('torch-examples-BL7nbael-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "418dc4828ae8fd12320d3d077affc9f3f6df7fd5336e79490ac2c5209cae2a53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
